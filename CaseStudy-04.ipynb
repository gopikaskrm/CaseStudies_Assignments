{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfghW7xXJduR",
        "outputId": "d200360a-554f-4b10-fa27-809799b62e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: unzip/content/Vegetables (copy).zip: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!unzip'/content/Vegetables (copy).zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os, shutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "tJOPm8aUMT0p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"vegetable-image-dataset/Vegetable Images/train\"\n",
        "validation_path = \"vegetable-image-dataset/Vegetable Images/validation\"\n",
        "test_path = \"vegetable-image-dataset/Vegetable Images/test\""
      ],
      "metadata": {
        "id": "9rqDZhEnMbUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_categories = os.listdir('vegetable-image-dataset/Vegetable Images/train')\n",
        "def plot_images(image_categories):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for i, cat in enumerate(image_categories):\n",
        "        image_path = train_path + '/' + cat\n",
        "        images_in_folder = os.listdir(image_path)\n",
        "        first_image_of_folder = images_in_folder[0]\n",
        "        first_image_path = image_path + '/' + first_image_of_folder\n",
        "        img = image.load_img(first_image_path)\n",
        "        img_arr = image.img_to_array(img)/255.0\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(img_arr)\n",
        "        plt.title(cat)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "plot_images(image_categories)"
      ],
      "metadata": {
        "id": "RgTO3r05NWJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "train_image_generator = train_gen.flow_from_directory(\n",
        "                                            train_path,\n",
        "                                            target_size=(150, 150),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='categorical')\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "val_image_generator = train_gen.flow_from_directory(\n",
        "                                            validation_path,\n",
        "                                            target_size=(150, 150),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='categorical')\n",
        "\n",
        "test_gen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "test_image_generator = train_gen.flow_from_directory(\n",
        "                                            test_path,\n",
        "                                            target_size=(150, 150),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='categorical')"
      ],
      "metadata": {
        "id": "6VMC0ocpOVqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_map = dict([(v, k) for k, v in train_image_generator.class_indices.items()])\n",
        "print(class_map)"
      ],
      "metadata": {
        "id": "aEtndugiN5dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[150, 150, 3]))\n",
        "model.add(MaxPooling2D(2, ))\n",
        "model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "8WsYB7V6Oxdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(patience=5) # Set up callbacks\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "hist = model.fit(train_image_generator,\n",
        "                 epochs=100,\n",
        "                 verbose=1,\n",
        "                 validation_data=val_image_generator,\n",
        "                 steps_per_epoch = 15000//32,\n",
        "                 validation_steps = 3000//32,\n",
        "                 callbacks=early_stopping)"
      ],
      "metadata": {
        "id": "w5e32U-TPBlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = 'vegetable-image-dataset/Vegetable Images/test/Broccoli/1011.jpg'\n",
        "\n",
        "def generate_predictions(test_image_path, actual_label):\n",
        "\n",
        "    test_img = image.load_img(test_image_path, target_size=(150, 150))\n",
        "    test_img_arr = image.img_to_array(test_img)/255.0\n",
        "    test_img_input = test_img_arr.reshape((1, test_img_arr.shape[0], test_img_arr.shape[1], test_img_arr.shape[2]))\n",
        "\n",
        "    predicted_label = np.argmax(model.predict(test_img_input))\n",
        "    predicted_vegetable = class_map[predicted_label]\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(test_img_arr)\n",
        "    plt.title(\"Predicted Label: {}, Actual Label: {}\".format(predicted_vegetable, actual_label))\n",
        "    plt.grid()\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "generate_predictions(test_image_path, actual_label='Brocoli')"
      ],
      "metadata": {
        "id": "FXhYFUJkPIIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJMk3nqzPa6-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}